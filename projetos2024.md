Sugestões dos principais temas e projetos (TCCs, ICs, ITs e orientações) voltados à Análise, Ciência de Dados e Aprendizado de Máquina, com foco aplicações:

#### 1. Séries Temporais (Aprendizado de Máquina e Inteligência Artificial) 

#### 2. Aplicação de Dados Abertos Centro de Rádio-Astronomia e Astrofísica Mackenzie (Desenvolvimento Web e em Nuvem)

#### 3. Análise de Dados Públicos sobre o Câncer (ou Dengue) no Estado de São Paulo (Ciência de Dados e Aprendizado de Máquina)

#### 4. Elastic Search, Coleta e Análise de Dados (Ciência de Dados e Aprendizado de Máquina)

#### 5. Detecção e Classificação de Imagens Médicas (Aprendizado de Máquina e Redes Neurais)

#### 6. Aplicação de Modelos Largos de Linguagem (IA ChatGPT, Bard).

Outros temas de interesse Detecção de Anomalias em Séries Temporais (https://hpi-information-systems.github.io/timeeval-evaluation-paper/ e https://scikit-learn.org/stable/modules/outlier_detection.html), modelos de Redes Sociais (Small-Worlds etc.) aplicados, Detecção de Poses Humanas em Imagens (https://github.com/CMU-Perceptual-Computing-Lab/openpose), Aplicações de Python para Finanças (Krastev, N. Python for Finance) etc.

<br>

Links e mais detalhes dos temas/projetos principais: 

1. **Séries Temporais**. Aplicação de modelos de aprendizado de máquina e modelos estatístico para a previsão e análise de Séries Temporais (preços de imóveis, demandas de produtos, movimento em estradas, consumo e produção de energia etc.). A ideia é trabalhar dados originais com uma ou mais das seguintes fontes: a) dados de empresas (anonimizados); b) coleta de dados por web scrapping ou api's; c) dados abertos do governo. As análises podem ser desenvolvidas em Python ou R, e os modelos básicos terão com base o livro Oliveira, R., Abarracin, O. Y. E., Silva, G. R. (2024) [Introdução às Séries Temporais: Uma Abordagem Prática em Python](https://github.com/Introducao-Series-Temporais-em-Python/Book) (in printing). Editora Mackenzie. Requisitos: Programação Python ou R.   

2. **Aplicação de Dados Abertos Centro de Rádio-Astronomia e Astrofísica Mackenzie**. Projeto de Desenvolvimento de Aplicação Web em Nuvem para disponibilidade de dados do CRAAM Centro de Rádio-Astronomia e Astrofísica Mackenzie. O CRAAM possui um grande número de dispositivos sensores como radio-telescópios, antenas GNSS e VLF, sensores meteorológicos,magnetômetros etc. No último ano desenvolvemos uma aplicação para disponibilizar de forma aberta os dados de VLF. Neste projeto essa plataforma deve ser expandida para dados de GNSS (sinais de GPS empregados em rádio astronomia) e implementar a alimentação automática dos dados dos dispositivos na nuvem (AWS). O projeto terá como base o trabalho Kauffmann, D.H.V, Santiago, L.S., Oliveira, R. (2023) [Open VLF: Plataforma de Dados Abertos para Very Low Frequency Data](https://github.com/open-vlf/academic/blob/main/Open%20VLF%20TCC.pdf), submetido para o Concurso de Teses e Trabalhos de Conclusão da SBSI 2024 (em andamento). Mais informações no GitHub do projeto https://github.com/open-vlf e no site da aplicação https://vlf-craam.web.app/. Requisitos: Conhecimentos de Desenvolvimento Web e uso de API's (AWS).

3. **Análise de Dados Públicos sobre o Câncer ou Dengue no Estado de São Paulo**. Trabalhar dados sobre Câncer no Estado de São Paulo disponibilizados pela Fundação Oncocentro de São Paulo (https://fosp.saude.sp.gov.br/fosp/diretoria-adjunta-de-informacao-e-epidemiologia/rhc-registro-hospitalar-de-cancer/banco-de-dados-do-rhc/). Haverá dois objetivos, podendo o projeto envolver um ou ambos: 1. Prover um dashboard de análise dos dados; 2. Previsão de estimativas de anos de vida e de anos de vida perdidos dos pacientes. As análises e previsões devem ser estratificadas por sexo, tipo de tumor, faixa etária etc. Dados públicos sobre Dengue podem ser encontrados em https://info.dengue.mat.br/. A onda recente de grande número de casos aumenta a importância de buscarmos modelos de predição de novos casos. Aqui, basicamente, deve-se trabalhar modelos Previsão de Séries Temporais. Requisitos: Conhecimentos de Python e de alguma ferramenta de Dashboard (desejável).

4. **Elastic Search, Coleta e Análise de Dados**. O ES (https://www.elastic.co/pt/) é uma ferramenta de coleta e análise de dados aberta e amplamente utilizada no mercado. A ideia desse projeto é empregar essa ferramenta para a coleta e detecção de anomalias em dados de sensores (como sensores de temperatura, humidade, consumo de energia etc.) ou científicos (dados de GPS, rádio-telescópios etc.). No momento há uma iniciação científica empregando o Elastic Search para coleta de dados de painéis solares da Hauwei do Mackenzie, e que deve ser o ponto de partida desse projeto, embora outros dados possam ser empregados. Requisitos: Conhecimentos básicos de ambientes operacionais para instalação do ES.

5. **Detecção e Classificação de Imagens Médicas**. Temos um andamento um projeto de avaliação de idade óssea a partir de radiografias e um TCC para diagnóstico de doenças de pele. São aplicações de IA, com uso de redes neurais e modelos pré-treinados para medicina e outros tipos de dados podem ser empregados. Para ter uma ideia dessa temática você pode acessar https://iopscience.iop.org/article/10.1088/1757-899X/982/1/012005/pdf. Aqui, preferencialmente, o aluno deve buscar uso de dados originais ainda não disponíveis publicamente. Requisitos: Sólido conhecimento de Python e já com algum conhecimento de modelos de aprendizado de máquina.

6. **Aplicação de Modelos Largos de Linguagem (ChatGPT, Bard)**. Empregar um grande modelo de linguagem para implementar de soluções com base em dados próprios de 'negócio' como construção de contratos ou descritivos de produtos padrão, análise de balanço ou de documentos de relação com investidores de empresas, Chat bot baseado em histórico de conversas etc. 
No momento, por exemplo, temos uma proposta de projeto em aprovação para construção de um Chat bot de orientação de pacientes com HIV baseado em conversas de Whatsapp do núcleo de orientação à AIDS no estado de São Paulo. Requisitos: conhecimentos de Python e acesso a dados próprios e originais.




